{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hand Gesture Detection using YOLOv8\n",
        "A comprehensive guide to implementing real-time hand gesture detection using YOLOv8 and Roboflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. [Introduction](#introduction)\n",
        "2. [Setup and Installation](#setup-and-installation)\n",
        "3. [Dataset Preparation](#dataset-preparation)\n",
        "4. [Model Training](#model-training)\n",
        "5. [Detection Functions](#detection-functions)\n",
        "   - [Image Detection](#image-detection)\n",
        "   - [Real-time Detection](#real-time-detection)\n",
        "6. [Usage Examples](#usage-examples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "This project implements a hand gesture detection system using YOLOv8 and Roboflow. It can perform real-time detection through a webcam feed and process individual images. The system can also save detection results as video files for later analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation\n",
        "First, install the required packages using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QspmfvGQwDTb"
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTS5NulRwkDl"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation\n",
        "Connect to Roboflow and download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efU3SzkIwzyg"
      },
      "outputs": [],
      "source": [
        "# Initialize Roboflow connection\n",
        "# Replace YOUR_API_KEY with your actual Roboflow API key\n",
        "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "# Access the project and download dataset\n",
        "project = rf.workspace(\"puspendu-ai-vision-workspace\").project(\"hand_gesture_detection-xdcpy\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note**: Make sure to replace `YOUR_API_KEY` with your actual Roboflow API key. You can obtain this from your Roboflow dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "Train the YOLOv8 model using the downloaded dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqtpmNfhxNRB"
      },
      "outputs": [],
      "source": [
        "# Initialize YOLO model\n",
        "model = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "# Train the model\n",
        "# Note: Update the data.yaml path with your absolute path\n",
        "model.train(\n",
        "    data=\"HAND_GESTURE_DETECTION-1/data.yaml\",\n",
        "    epochs=50,\n",
        "    imgsz=640\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Important**: \n",
        "> - The `data.yaml` file path should be updated with the absolute path of your dataset\n",
        "> - Training time will vary based on your hardware capabilities\n",
        "> - Using GPU acceleration is recommended for faster training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detection Functions\n",
        "\n",
        "### Image Detection\n",
        "Function to display predictions on single images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmAof3CfH6c5"
      },
      "outputs": [],
      "source": [
        "def display_prediction(image_path):\n",
        "    \"\"\"\n",
        "    Display detection results for a single image.\n",
        "    \n",
        "    Args:\n",
        "        image_path (str): Path to the input image\n",
        "        \n",
        "    Returns:\n",
        "        None: Displays the image with detection results\n",
        "    \"\"\"\n",
        "    trained_model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "    result = trained_model.predict(image_path, conf=0.5)\n",
        "    img_rgb = cv.cvtColor(result[0].plot(), cv.COLOR_BGR2RGB)\n",
        "    \n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Real-time Detection\n",
        "Enhanced function for real-time webcam detection with video saving capability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_detection(conf=0.5, save_video=False, filename=None):\n",
        "    \"\"\"\n",
        "    Run real-time object detection on webcam feed using YOLOv8 model.\n",
        "\n",
        "    Parameters:\n",
        "    - conf: Confidence threshold for detections (default: 0.5)\n",
        "    - save_video: Flag to save output as a video file (default: False)\n",
        "    - filename: Optional filename for saved video. If None, an incremented filename is generated.\n",
        "    \"\"\"\n",
        "    # Load the model\n",
        "    try:\n",
        "        model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    # Handle filename for saving video\n",
        "    if save_video:\n",
        "        if filename is None:\n",
        "            # Generate an auto-incremented filename if none provided\n",
        "            count = 1\n",
        "            while os.path.exists(f\"VIDEOS/detection_result_{count}.mp4\"):\n",
        "                count += 1\n",
        "            filename = f\"VIDEOS/detection_result_{count}.mp4\"\n",
        "        else:\n",
        "            # Ensure .mp4 extension if user specifies filename\n",
        "            if not filename.endswith(\".mp4\"):\n",
        "                filename += \".mp4\"\n",
        "            filename = f\"VIDEOS/{filename}\"\n",
        "\n",
        "        print(f\"Recording video to {filename}\")\n",
        "\n",
        "    # Start video capture\n",
        "    cap = cv.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: couldn't open the webcam!\")\n",
        "        return\n",
        "\n",
        "    # Capture frame width, height, and set fps\n",
        "    w, h = (int(cap.get(x)) for x in (3, 4))\n",
        "    fps = 15\n",
        "    out = None\n",
        "\n",
        "    # Set up video writer if saving is enabled\n",
        "    if save_video:\n",
        "        out = cv.VideoWriter(filename, cv.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "    print(\"Press 's' to start saving, 'p' to pause and exit.\")\n",
        "\n",
        "    # Main loop to read frames and perform detection\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: couldn't read a frame from the webcam.\")\n",
        "            break\n",
        "\n",
        "        # Flip the frame horizontally\n",
        "        frame = cv.flip(frame, 1)\n",
        "\n",
        "        # Run YOLO model prediction\n",
        "        try:\n",
        "            result = model.predict(frame, conf=conf, verbose=False)[0]\n",
        "            frame = result.plot()\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model prediction: {e}\")\n",
        "            break\n",
        "\n",
        "        # Display the frame\n",
        "        cv.imshow(\"Camera\", frame)\n",
        "\n",
        "        # Handle user input\n",
        "        key = cv.waitKey(1) & 0xFF\n",
        "        if key == ord('s') and save_video:\n",
        "            print(\"Video recording started.\")\n",
        "        elif key == ord('p'):\n",
        "            print(\"Stopping and closing the program.\")\n",
        "            break\n",
        "\n",
        "        # Save frame if enabled\n",
        "        if save_video and out is not None:\n",
        "            out.write(frame)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    if out:\n",
        "        out.release()\n",
        "    cv.destroyAllWindows()\n",
        "    print(\"Program ended and resources released.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Features**:\n",
        "> - Real-time detection through webcam\n",
        "> - Adjustable confidence threshold\n",
        "> - Optional video saving\n",
        "> - Horizontal frame flipping for natural interaction\n",
        "> - Error handling and resource management\n",
        "> - Simple keyboard controls ('s' to start saving, 'p' to pause/exit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Examples\n",
        "\n",
        "1. Run real-time detection without saving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_detection(conf=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Run detection and save video with auto-generated filename:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_detection(conf=0.5, save_video=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Run detection and save video with custom filename:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_detection(conf=0.5, save_video=True, filename=\"my_detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Process a single image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_prediction(\"path/to/your/image.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Best Practices**:\n",
        "> - Ensure good lighting conditions for better detection\n",
        "> - Keep hand gestures within the camera frame\n",
        "> - Try to capture videos with a background as shown in the test images\n",
        "> - While recording videos try to show only your hands not faces as the model is trained only with hand images\n",
        "> - Adjust confidence threshold based on your needs\n",
        "> - Create a 'VIDEOS' directory before saving recordings\n",
        "> - Regularly backup your trained models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project link\n",
        " - You can find the project on Roboflow by clicking [here](https://universe.roboflow.com/puspendu-ai-vision-workspace/hand_gesture_detection-xdcpy)\n",
        " - You can find the training logs on on wandb by clicking on this [link](https://wandb.ai/ranapuspendu24-iit-madras-foundation/Ultralytics/runs/zayjstbb?nw=nwuserranapuspendu24)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
